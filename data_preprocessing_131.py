# -*- coding: utf-8 -*-
"""DATA-PREPROCESSING_131

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UFvNaguiDt0w5x4nttOJMKZGQfYQbHVi
"""

import pandas as pd
import numpy as np

# Load dataset from GitHub mirror (CSV format)
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
columns = [
    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
    'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'
]
df = pd.read_csv(url, names=columns)

# Replace 0s with NaN in columns that shouldn't be 0
cols_with_invalid_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
df[cols_with_invalid_zeros] = df[cols_with_invalid_zeros].replace(0, np.nan)

# Show missing values count
print("Missing values before filling:")
print(df.isnull().sum())

# Fill missing values with mean
df.fillna(df.mean(), inplace=True)

# Show that missing values are handled
print("\nMissing values after filling:")
print(df.isnull().sum())

# Fill missing values using column mean
df.fillna(df.mean(), inplace=True)

# Show missing values count after filling
print("\n‚úÖ Missing values after filling:")
print(df.isnull().sum())

# Check for duplicate rows
duplicates = df.duplicated()
print("üîç Number of duplicate rows:", duplicates.sum())

# Optional: View the duplicates (if any)
if duplicates.sum() > 0:
    print("\nDuplicate rows:")
    print(df[duplicates])

# Remove duplicate rows
df.drop_duplicates(inplace=True)

# Confirm removal
print("\n‚úÖ New shape after removing duplicates:", df.shape)

from sklearn.preprocessing import MinMaxScaler, StandardScaler

# Drop the target column 'Outcome' while scaling features
features = df.drop('Outcome', axis=1)
target = df['Outcome']

# --- Normalization (Min-Max Scaling) ---
minmax_scaler = MinMaxScaler()
normalized = minmax_scaler.fit_transform(features)
normalized_df = pd.DataFrame(normalized, columns=features.columns)

print("üîπ Normalized Data (0 to 1 scale):")
print(normalized_df.head())

# --- Standardization (Z-score Scaling) ---
standard_scaler = StandardScaler()
standardized = standard_scaler.fit_transform(features)
standardized_df = pd.DataFrame(standardized, columns=features.columns)

print("\nüîπ Standardized Data (mean=0, std=1):")
print(standardized_df.head())

import matplotlib.pyplot as plt
import seaborn as sns

# Use standardized data for visualization
data = standardized_df.copy()

# Visualize outliers using boxplots
plt.figure(figsize=(15, 8))
sns.boxplot(data=data)
plt.title("üîç Boxplot for Outlier Detection")
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Use standardized data for visualization
data = standardized_df.copy()

# Visualize outliers using boxplots
plt.figure(figsize=(15, 8))
sns.boxplot(data=data)
plt.title("üîç Boxplot for Outlier Detection")
plt.xticks(rotation=45)
plt.show()

# IQR-based outlier removal
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

df_no_outliers = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

import matplotlib.pyplot as plt
import seaborn as sns

# Add back the Outcome column if needed
df_no_outliers['Outcome'] = df['Outcome']

# Compute correlation matrix
corr = df_no_outliers.corr()

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("üîç Feature Correlation Heatmap with Outcome")
plt.show()

# Select top 5 features based on correlation
selected_columns = ['Glucose', 'Age', 'BMI', 'Pregnancies', 'DiabetesPedigreeFunction', 'Outcome']

# Final dataset with only top features
df_selected = df[selected_columns]

print("‚úÖ New shape of selected feature dataset:", df_selected.shape)
print(df_selected.head())

# Create bins for Age
age_bins = [0, 30, 50, 100]
age_labels = ['Young', 'Middle-aged', 'Old']
df_selected['Age_Group'] = pd.cut(df_selected['Age'], bins=age_bins, labels=age_labels)

# Create bins for Glucose
glucose_bins = [0, 90, 140, 200]
glucose_labels = ['Low', 'Normal', 'High']
df_selected['Glucose_Level'] = pd.cut(df_selected['Glucose'], bins=glucose_bins, labels=glucose_labels)

# Show result
print(df_selected[['Age', 'Age_Group', 'Glucose', 'Glucose_Level']].head())

from sklearn.model_selection import train_test_split

# Drop non-numeric columns (like Age_Group, Glucose_Level)
X = df_selected.drop(['Outcome', 'Age_Group', 'Glucose_Level'], axis=1)
y = df_selected['Outcome']

# Split dataset (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Show result
print("‚úÖ Training Set Shape:", X_train.shape)
print("‚úÖ Testing Set Shape:", X_test.shape)

import matplotlib.pyplot as plt

# Plot histograms of original vs scaled features
df[['Glucose', 'Age', 'BMI']].hist(figsize=(10, 6), bins=15)
plt.suptitle("üìä Original Feature Distributions")
plt.show()

normalized_df[['Glucose', 'Age', 'BMI']].hist(figsize=(10, 6), bins=15)
plt.suptitle("üìä Normalized Feature Distributions")
plt.show()

import seaborn as sns

plt.figure(figsize=(10, 6))
sns.boxplot(data=df[['Glucose', 'Age', 'BMI']])
plt.title("üì¶ Boxplot for Outlier Detection")
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("üî• Feature Correlation with Outcome")
plt.show()

sns.countplot(x='Age_Group', hue='Outcome', data=df_selected)
plt.title("üë∂ Age Group vs Diabetes Outcome")
plt.show()

sns.countplot(x='Glucose_Level', hue='Outcome', data=df_selected)
plt.title("üç≠ Glucose Level vs Diabetes Outcome")
plt.show()

df['Outcome'].value_counts().plot(kind='pie', autopct='%1.1f%%', labels=['No Diabetes', 'Diabetes'])
plt.title("‚öñÔ∏è Outcome Class Distribution")
plt.ylabel("")
plt.show()